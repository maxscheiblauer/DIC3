{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "import detect\n",
    "#import tflite as tf\n",
    "import platform\n",
    "import datetime\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import io\n",
    "from io import BytesIO\n",
    "from flask import Flask, request, Response, jsonify\n",
    "import random\n",
    "import re\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\maxsc\\Desktop\\TU\\DIC3\\Pictures_small'\n",
    "images_s = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Check if the file is a JPEG image\n",
    "    if os.path.isfile(file_path) and filename.lower().endswith(\".jpg\"):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            # Read the image data\n",
    "            image_data = file.read()\n",
    "\n",
    "            # Encode the image data as base64\n",
    "            encoded_data = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "            # Append the encoded string to the list\n",
    "            images_s.append(encoded_data)\n",
    "\n",
    "print(len(images_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess ONE image\n",
    "\n",
    "\n",
    "#example = images_s[32]\n",
    "\n",
    "#image_bytes = base64.b64decode(example)\n",
    "#image = Image.open(io.BytesIO(image_bytes))\n",
    "#image = image.resize((300, 300))  # Resize to match the model's input size\n",
    "#image_np = np.array(image).astype(np.float32)  # Convert PIL image to NumPy array\n",
    "\n",
    "#image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#image_np = image_np.astype(np.float32)\n",
    "#image_np = np.expand_dims(image_np, axis=0)\n",
    "imgs = []\n",
    "\n",
    "for i in images_s:\n",
    "    image_bytes = base64.b64decode(i)\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.resize((300, 300))  # Resize to match the model's input size\n",
    "    image_np = np.array(image).astype(np.float32)  # Convert PIL image to NumPy array\n",
    "    imgs.append(image_np)\n",
    "\n",
    "\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "#Load detector model\n",
    "\n",
    "model_path = r\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "detector = hub.load(model_path).signatures['default']\n",
    "\n",
    "\n",
    "#IGNORE THIS PART\n",
    "#interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "#interpreter.allocate_tensors()\n",
    "\n",
    "#Example image\n",
    "#input_tensor = interpreter.get_input_details()[0]['index']\n",
    "#interpreter.set_tensor(input_tensor, image_np)\n",
    "\n",
    "#interpreter.invoke()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 objects.\n",
      "Inference time:  81.36582040786743\n"
     ]
    }
   ],
   "source": [
    "#CODE TO DO OBJECT DETECTION ON ONE IMAGE\n",
    "img_nr = 4\n",
    "\n",
    "\n",
    "converted_img  = tf.image.convert_image_dtype(imgs[img_nr], tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "start_time = time.time()\n",
    "result = detector(converted_img)\n",
    "end_time = time.time()\n",
    "result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "print(\"Inference time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT RELEVANT RIGHT NOW\n",
    "# Get the output tensors\n",
    "output_details = interpreter.get_output_details()\n",
    "boxes = interpreter.get_tensor(output_details[0]['index'])\n",
    "classes = interpreter.get_tensor(output_details[1]['index'])\n",
    "scores = interpreter.get_tensor(output_details[2]['index'])\n",
    "num_detections = int(output_details[3]['index'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT RELEVANT RIGHT NOW\n",
    "# Filter out detections with low confidence\n",
    "threshold = 0.5\n",
    "detections = []\n",
    "for i in range(num_detections):\n",
    "    if scores[0][i] > threshold:\n",
    "        class_id = int(classes[0][i])\n",
    "        class_name = label_map[class_id]\n",
    "        box = boxes[0][i]\n",
    "        detection = {\n",
    "            'class': class_name,\n",
    "            'score': float(scores[0][i]),\n",
    "            'box': [float(box[0]), float(box[1]), float(box[2]), float(box[3])]\n",
    "        }\n",
    "        detections.append(detection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
